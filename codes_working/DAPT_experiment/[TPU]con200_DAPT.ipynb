{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec7e8c6-6229-4475-b3f7-bca2c94209c7",
   "metadata": {},
   "source": [
    "### Install library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd33494c-7065-4f6e-8ef0-d623829fddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers[sentencepiece]\n",
    "# !pip install torch/xla\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install torch\n",
    "# !pip install -q soynlp emoji==1.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f31aa-bb01-4dba-9b48-bd21043c1543",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0622f69e-ee28-4cdc-a935-70ada61945bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0+cu102\n",
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "print(torch.__version__)\n",
    "print(emoji.__version__)\n",
    "\n",
    "random.seed(2022)\n",
    "torch.manual_seed(2022)\n",
    "np.random.seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "432c0f8c-8ae7-4ad4-96d8-210137c99068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 02:12:50.430391: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-14 02:12:50.614575: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2022-09-14 02:12:50.614599: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-14 02:12:50.648708: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-14 02:12:51.508328: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2022-09-14 02:12:51.508455: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2022-09-14 02:12:51.508465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import LineByLineTextDataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "# from transformers import TrainingArguments\n",
    "# from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7d2281f-ab0a-4004-b904-48d9df88e704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10\n"
     ]
    }
   ],
   "source": [
    "# using TPU through torch\n",
    "import torch_xla\n",
    "import torch_xla.utils.utils as xu\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.utils.serialization as xser\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "\n",
    "print(torch_xla.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4900a9-3448-4d54-b268-423307b9c45c",
   "metadata": {},
   "source": [
    "### TPU setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa8371f2-076f-4bc2-865d-69cc0345e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## .pyÎèåÎ¶¥ Îïå,\n",
    "#!export XRT_TPU_CONFIG=\"localservice;0;localhost:51011\"\n",
    "import os\n",
    "os.environ['XRT_TPU_CONFIG'] = \"localservice;0;localhost:51011\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b99bfd-3518-4d70-879e-809dfadaadb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 02:12:53.743677: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2022-09-14 02:12:53.743729: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n"
     ]
    }
   ],
   "source": [
    "device = xm.xla_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a00c752-682e-4c87-8920-bb06c9e55f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='xla', index=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9de0a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TPU:0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xm.xla_real_devices([str(device)])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fabc9b-a803-49b8-80e6-bf31545fad6d",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c1da4b-a213-424b-9196-3889b44eaba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"klue/roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38431540-fb21-49cc-b2a5-dba25eb801a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>>  KLUE_RoBERTa_large number of parameters : 337M'\n"
     ]
    }
   ],
   "source": [
    "klue_roberta_large_parameters = model.num_parameters() / 1_000_000\n",
    "print(f\"'>>>  KLUE_RoBERTa_large number of parameters : {round(klue_roberta_large_parameters)}M'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aee184-4058-4213-a088-db3c2d4d4f81",
   "metadata": {},
   "source": [
    "### Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "580e0afe-16cd-491d-b587-d8d96286dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7adbf449-2ac1-464c-b410-7083a763c734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"klue/roberta-large\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 1024,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4096,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"tokenizer_class\": \"BertTokenizer\",\n",
       "  \"transformers_version\": \"4.21.3\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b05fb239-4821-411d-bc0e-47efe854598f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method PreTrainedTokenizerFast.tokenize of PreTrainedTokenizerFast(name_or_path='klue/roberta-large', vocab_size=32000, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcfd47f",
   "metadata": {},
   "source": [
    "### normal Langauge Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe6fee2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ïù¥Î¶ÑÎßå ÎπºÍ≥† Îã§Ïû†Ïò∑Ïù¥Îã§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ï§ëÍ∞ÑÏóê Ïã†Ïùò ÌåêÍ≤∞Ïù¥ Îçî ÏßÄÎãàÏñ¥ ÌçΩÌçΩ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ïù¥Î¶Ñ Î™©ÏÜåÎ¶¨Í∞Ä Ï¢Ä Îã¨ÎùºÏßÑÍ±¥ Í∏∞Î∂ÑÌÉñ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ï§ëÍ∞ÑÏóê ÌèâÏ∞Ω ÎßêÌï†Îïå ÌèâÏ∞ΩÏò¨Î¶ºÌîΩ ÌïòÎäîÏ§Ñ ÏòÅÎØ∏ÌçºÎ≤ÑÎ≤ÑÎ≤ÑÎ≤ÑÎ≤Ö</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ïî®Í∑∏ÎßàÍ∞Ä ÏãúÍ∑∏ÎÑêÎ°ú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604648</th>\n",
       "      <td>Ï†ÄÎü∞Í±∞ Î®πÏúºÎ©¥ Í∑ÄÏó¨ÏõåÏßÄÎÇò</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604649</th>\n",
       "      <td>ÎÇ¥ÍπåÍπå Í∑ÄÏóº</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604650</th>\n",
       "      <td>ÎÇòÎèÑ ÎπÑÏÜçÏñ¥ Ï¢ãÏïÑÌïòÎäîÎç∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604651</th>\n",
       "      <td>Ï†ÄÏ†àÎ°ú ÏõÉÏùåÏù¥ ÎÇòÏò¥ ÎÑò Í∑ÄÏó¨Ïõå</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604652</th>\n",
       "      <td>Ïô§Ï∫ê Ï°∞Í∑ÄÎãà</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>604653 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 text\n",
       "0                        Ïù¥Î¶ÑÎßå ÎπºÍ≥† Îã§Ïû†Ïò∑Ïù¥Îã§\n",
       "1                 Ï§ëÍ∞ÑÏóê Ïã†Ïùò ÌåêÍ≤∞Ïù¥ Îçî ÏßÄÎãàÏñ¥ ÌçΩÌçΩ\n",
       "2                  Ïù¥Î¶Ñ Î™©ÏÜåÎ¶¨Í∞Ä Ï¢Ä Îã¨ÎùºÏßÑÍ±¥ Í∏∞Î∂ÑÌÉñ\n",
       "3       Ï§ëÍ∞ÑÏóê ÌèâÏ∞Ω ÎßêÌï†Îïå ÌèâÏ∞ΩÏò¨Î¶ºÌîΩ ÌïòÎäîÏ§Ñ ÏòÅÎØ∏ÌçºÎ≤ÑÎ≤ÑÎ≤ÑÎ≤ÑÎ≤Ö\n",
       "4                           Ïî®Í∑∏ÎßàÍ∞Ä ÏãúÍ∑∏ÎÑêÎ°ú\n",
       "...                               ...\n",
       "604648                  Ï†ÄÎü∞Í±∞ Î®πÏúºÎ©¥ Í∑ÄÏó¨ÏõåÏßÄÎÇò\n",
       "604649                         ÎÇ¥ÍπåÍπå Í∑ÄÏóº\n",
       "604650                   ÎÇòÎèÑ ÎπÑÏÜçÏñ¥ Ï¢ãÏïÑÌïòÎäîÎç∞\n",
       "604651               Ï†ÄÏ†àÎ°ú ÏõÉÏùåÏù¥ ÎÇòÏò¥ ÎÑò Í∑ÄÏó¨Ïõå\n",
       "604652                         Ïô§Ï∫ê Ï°∞Í∑ÄÎãà\n",
       "\n",
       "[604653 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = pd.read_csv('conversation_data.csv',encoding='utf-8')\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb55e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df): #Ï†ÑÏ≤òÎ¶¨ ÏΩîÎìú\n",
    "    emojis = ''.join(emoji.UNICODE_EMOJI.keys())\n",
    "    pattern = re.compile(f'[^ .,?!/@$%~ÔºÖ¬∑‚àº()\\x00-\\x7F„Ñ±-Ìû£]+')\n",
    "    url_pattern = re.compile(\n",
    "        r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
    "    \n",
    "    x_list = []\n",
    "    for x in conv.text:\n",
    "        x = str(x)\n",
    "        x = pattern.sub(' ', x)\n",
    "        x = url_pattern.sub('', x)\n",
    "        x = x.strip()\n",
    "        x = repeat_normalize(x, num_repeats=2) # „Öã„Öã„Öã„Öã„Öã„Öã .. -> „Öã„Öã Í∞ôÏù¥ Î∞òÎ≥µÎêòÎäî Î¨∏ÏûêÏóê ÎåÄÌï¥ Î≥ÄÌôò \n",
    "        x_list.append(x)\n",
    "    return x_list\n",
    "pre_conv = preprocess(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e889278",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in pre_conv:\n",
    "    if len(i) <= 200:\n",
    "        result.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "581e1175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592017"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2e1dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(result)\n",
    "res.columns = ['text']\n",
    "res.to_csv('conv.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2670249a-a796-4bd8-9a2a-50127f702eea",
   "metadata": {},
   "source": [
    "### Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5794312b-4b2f-4430-9888-65dd00468576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wjswps/.local/lib/python3.8/site-packages/transformers/data/datasets/language_modeling.py:121: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# default loading option = \"utf-8\"\n",
    "block_size = 512        # 256, 384, 512 \n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path='conv.csv',\n",
    "    block_size=block_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67dc70ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.data.datasets.language_modeling.LineByLineTextDataset at 0x7f5fd94a8700>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da532fae-7294-45b8-92fd-625c8376729a",
   "metadata": {},
   "source": [
    "### Define the data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8061ed26-2a40-4b66-a7fe-496fac838ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b9e1f6-ab86-44b4-b284-a7db208b09a0",
   "metadata": {},
   "source": [
    "### Model to tpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ef1d1de-e33e-4f84-8545-1e62b7f12049",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408beb7f-8a3a-433d-83ba-428c2b33299b",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8402304a-8551-4d24-b09f-87ad17e5883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "/home/wjswps/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 592018\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12500' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12500/12500 4:07:02, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.792700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.708900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.670100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.654900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.564100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>3.579000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.604400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>3.409500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.412700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>3.384400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.318800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>3.251200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>3.224600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.205300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>3.179600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>3.116300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.043200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>3.036600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>3.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>3.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.923200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>2.953800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-500\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-500/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-1000\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-1000/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-1500\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-1500/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-2000\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-2000/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-2500\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-2500/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-2500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-3000\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-3000/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-3000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-3500\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-3500/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-3500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-4000\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-4000/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-4000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-4500\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-4500/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-4500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-5000\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-5000/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-5000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-5500\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-5500/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-5500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-6000\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-6000/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-6000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-6500\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-6500/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-6500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-7000\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-7000/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-7000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-7500\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-7500/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-7500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-6500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-8000\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-8000/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-8000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-8500\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-8500/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-8500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-9000\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-9000/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-9000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-9500\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-9500/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-9500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-8500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-10000\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-10000/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-10000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-10500\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-10500/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-10500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-9500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-11000\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-11000/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-11000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-11500\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-11500/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-11500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-10500] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-12000\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-12000/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-12000/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-11000] due to args.save_total_limit\n",
      "Saving model checkpoint to test_mlm/16_512_20000_e8/checkpoint-12500\n",
      "Configuration saved in test_mlm/16_512_20000_e8/checkpoint-12500/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/checkpoint-12500/pytorch_model.bin\n",
      "Deleting older checkpoint [test_mlm/16_512_20000_e8/checkpoint-11500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 14824.021312475204\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "batch_size = 16        # 8, 16, 32\n",
    "num_train_epochs = 8\n",
    "trained_model_path = f\"test_mlm/{batch_size}_{block_size}_20000_e8\"\n",
    "\n",
    "# os.mkdir(trained_model_path)\n",
    "\n",
    "'''\n",
    "TrainingArguments parameters\n",
    "https://github.com/huggingface/transformers/blob/main/src/transformers/training_args.py\n",
    "'''\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=trained_model_path,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=num_train_epochs,                 # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,      # batch size per device during training\n",
    "    save_total_limit=2,\n",
    "    weight_decay = 0.01,\n",
    "    tpu_num_cores = 85,\n",
    "    seed = 2022,\n",
    "    data_seed = 2022,\n",
    "    dataloader_pin_memory = True,\n",
    "    max_steps = 12_500\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f93741e-51a6-4f1c-abe5-12d300637c4a",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b2c7611-b81d-4ef1-9f9d-a5b345659fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test_mlm/16_512_20000_e8\n",
      "Configuration saved in test_mlm/16_512_20000_e8/config.json\n",
      "Model weights saved in test_mlm/16_512_20000_e8/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(trained_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a48ec0b-9f02-4ac0-9ebe-38b3cae20ee4",
   "metadata": {},
   "source": [
    "#### The impact of Block size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a9791-a0ef-43f2-a38e-54978561c7d8",
   "metadata": {},
   "source": [
    "| Block size | Epochs | Batch size | Total step | Loss | Time |\n",
    "| - | - | - | - | - | - |\n",
    "| 256 | 2 | 16 | 10336 | 2.? | |\n",
    "| 384 |  | | | | |\n",
    "| 512 |  | | | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577f1935-fc40-4361-80b4-cb1a11a7f75f",
   "metadata": {},
   "source": [
    "#### The impact of Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dea75e4-06c7-4a96-a36a-35d26a57f8a9",
   "metadata": {},
   "source": [
    "| Block size | Epochs | Batch size | Total step | Loss | Time |\n",
    "| - | - | - | - | - | - |\n",
    "| 512 |  | 8 |  |  | |\n",
    "| 512 |  | 16 | | |  |\n",
    "| 512 |  | 32 | | | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f36bfc2-eec4-4253-90e4-bbbd4ce1e13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wjswps/.local/lib/python3.8/site-packages/huggingface_hub/utils/_deprecation.py:38: FutureWarning: Deprecated positional argument(s) used in 'create_repo': pass token='checkpoint-12500' as keyword args. From version 0.12 passing these as positional arguments will result in an error,\n",
      "  warnings.warn(\n",
      "/home/wjswps/.local/lib/python3.8/site-packages/huggingface_hub/hf_api.py:681: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
      "  warnings.warn(\n",
      "Cloning https://huggingface.co/qlqqqk/checkpoint-12500 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369e844b4c854bdca103f2d5a6af3280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 32.0k/1.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## repo\n",
    "MODEL_SAVE_REPO = 'klue_batch16_block512_con200' # ex) 'my-bert-fine-tuned'\n",
    "HUGGINGFACE_AUTO_TOKEN = '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' # https://huggingface.co/settings/token\n",
    " \n",
    "## Push to huggingface-hub\n",
    "model.push_to_hub(\n",
    "\t\t\t'test_mlm/16_512_20000_e8/checkpoint-12500', \n",
    "\t\t\tuse_temp_dir=True, \n",
    "\t\t\tuse_auth_token=HUGGINGFACE_AUTO_TOKEN\n",
    ")\n",
    "tokenizer.push_to_hub(\n",
    "\t\t\t'test_mlm/16_512_20000_e8/checkpoint-12500', \n",
    "\t\t\tuse_temp_dir=True, \n",
    "\t\t\tuse_auth_token=HUGGINGFACE_AUTO_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccffe29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
